"""
Reliable Authentic ML Ensemble
Uses only stable, dependency-free models trained on authentic dataset
"""

import pandas as pd
import numpy as np
import logging
from typing import Dict, List, Optional
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB

logger = logging.getLogger(__name__)

class ReliableAuthenticEnsemble:
    """Reliable ML ensemble using only stable scikit-learn models"""
    
    def __init__(self):
        self.models = {}
        self.scaler = StandardScaler()
        self.team_elo = {}
        self.df = None
        self.is_initialized = False
        self.model_names = []
        
    async def initialize(self):
        """Initialize all reliable ML models with authentic dataset"""
        try:
            logger.info("üèÜ Loading comprehensive football dataset for reliable ML ensemble...")
            
            # Load the comprehensive dataset
            self.df = pd.read_csv('football_data/data/Matches.csv', low_memory=False)
            logger.info(f"üìä Loaded {len(self.df)} authentic matches for ML training")
            
            # Build team Elo ratings
            self._build_team_elo_ratings()
            
            # Prepare training data
            X, y = self._prepare_training_data()
            
            if len(X) == 0:
                logger.error("‚ùå No training data available")
                return
            
            # Split data
            X_train, X_test, y_train, y_test = train_test_split(
                X, y, test_size=0.2, random_state=42, stratify=y
            )
            
            # Scale features
            X_train_scaled = self.scaler.fit_transform(X_train)
            X_test_scaled = self.scaler.transform(X_test)
            
            # Train all reliable models
            await self._train_random_forest(X_train_scaled, X_test_scaled, y_train, y_test)
            await self._train_gradient_boosting(X_train_scaled, X_test_scaled, y_train, y_test)
            await self._train_logistic_regression(X_train_scaled, X_test_scaled, y_train, y_test)
            await self._train_knn(X_train_scaled, X_test_scaled, y_train, y_test)
            await self._train_naive_bayes(X_train_scaled, X_test_scaled, y_train, y_test)
            
            self.is_initialized = True
            logger.info(f"‚úÖ Reliable ML ensemble ready with {len(self.model_names)} models: {', '.join(self.model_names)}")
            
        except Exception as e:
            logger.error(f"‚ùå Error initializing ML ensemble: {e}")
            
    async def generate_ensemble_prediction(self, home_team: str, away_team: str) -> Dict:
        """Generate prediction using ensemble of reliable trained models"""
        try:
            if not self.is_initialized:
                return {
                    'error': 'ML ensemble not initialized',
                    'home_win': 33.3,
                    'away_win': 33.3,
                    'draw': 33.4,
                    'confidence': 0.0
                }
            
            # Extract features
            features = self._extract_features(home_team, away_team)
            if features is None:
                return {
                    'error': 'Teams not found in authentic database',
                    'home_win': 33.3,
                    'away_win': 33.3,
                    'draw': 33.4,
                    'confidence': 0.0
                }
            
            # Scale features
            scaled_features = self.scaler.transform([features])
            
            # Get predictions from all models
            predictions = {}
            
            for model_name, model in self.models.items():
                try:
                    pred = model.predict_proba(scaled_features)[0]
                    predictions[model_name] = pred
                except Exception as e:
                    logger.warning(f"Error getting prediction from {model_name}: {e}")
            
            # Ensemble prediction (average of all models)
            if predictions:
                ensemble_pred = np.mean(list(predictions.values()), axis=0)
                
                home_win = float(ensemble_pred[0] * 100)
                away_win = float(ensemble_pred[1] * 100)
                draw = float(ensemble_pred[2] * 100)
                
                confidence = float(np.max(ensemble_pred))
                
                return {
                    'home_win': home_win,
                    'away_win': away_win,
                    'draw': draw,
                    'confidence': confidence,
                    'model_breakdown': {model: pred.tolist() for model, pred in predictions.items()},
                    'ensemble_method': 'weighted_average',
                    'models_used': list(predictions.keys()),
                    'model_count': len(predictions),
                    'data_source': 'authentic_228k_matches_2000_2025',
                    'historical_matches': self._get_h2h_count(home_team, away_team)
                }
            else:
                return {
                    'error': 'No models available',
                    'home_win': 33.3,
                    'away_win': 33.3,
                    'draw': 33.4,
                    'confidence': 0.0
                }
                
        except Exception as e:
            logger.error(f"‚ùå Error generating ensemble prediction: {e}")
            return {
                'error': str(e),
                'home_win': 33.3,
                'away_win': 33.3,
                'draw': 33.4,
                'confidence': 0.0
            }
    
    async def _train_random_forest(self, X_train, X_test, y_train, y_test):
        """Train Random Forest model"""
        try:
            logger.info("üå≥ Training Random Forest on authentic data...")
            
            self.models['random_forest'] = RandomForestClassifier(
                n_estimators=100,
                max_depth=10,
                random_state=42,
                n_jobs=1  # Single thread to avoid dependency issues
            )
            
            self.models['random_forest'].fit(X_train, y_train)
            accuracy = self.models['random_forest'].score(X_test, y_test)
            logger.info(f"‚úÖ Random Forest accuracy: {accuracy:.3f}")
            self.model_names.append('Random Forest')
            
        except Exception as e:
            logger.error(f"‚ùå Error training Random Forest: {e}")
    
    async def _train_gradient_boosting(self, X_train, X_test, y_train, y_test):
        """Train Gradient Boosting model"""
        try:
            logger.info("üöÄ Training Gradient Boosting on authentic data...")
            
            self.models['gradient_boosting'] = GradientBoostingClassifier(
                n_estimators=100,
                max_depth=6,
                learning_rate=0.1,
                random_state=42
            )
            
            self.models['gradient_boosting'].fit(X_train, y_train)
            accuracy = self.models['gradient_boosting'].score(X_test, y_test)
            logger.info(f"‚úÖ Gradient Boosting accuracy: {accuracy:.3f}")
            self.model_names.append('Gradient Boosting')
            
        except Exception as e:
            logger.error(f"‚ùå Error training Gradient Boosting: {e}")
    
    async def _train_logistic_regression(self, X_train, X_test, y_train, y_test):
        """Train Logistic Regression model"""
        try:
            logger.info("üìà Training Logistic Regression on authentic data...")
            
            self.models['logistic_regression'] = LogisticRegression(
                random_state=42,
                max_iter=1000,
                multi_class='multinomial',
                solver='lbfgs'
            )
            
            self.models['logistic_regression'].fit(X_train, y_train)
            accuracy = self.models['logistic_regression'].score(X_test, y_test)
            logger.info(f"‚úÖ Logistic Regression accuracy: {accuracy:.3f}")
            self.model_names.append('Logistic Regression')
            
        except Exception as e:
            logger.error(f"‚ùå Error training Logistic Regression: {e}")
    
    async def _train_knn(self, X_train, X_test, y_train, y_test):
        """Train K-Nearest Neighbors model"""
        try:
            logger.info("üéØ Training K-Nearest Neighbors on authentic data...")
            
            self.models['knn'] = KNeighborsClassifier(
                n_neighbors=15,
                weights='distance',
                n_jobs=1  # Single thread to avoid dependency issues
            )
            
            self.models['knn'].fit(X_train, y_train)
            accuracy = self.models['knn'].score(X_test, y_test)
            logger.info(f"‚úÖ K-Nearest Neighbors accuracy: {accuracy:.3f}")
            self.model_names.append('K-Nearest Neighbors')
            
        except Exception as e:
            logger.error(f"‚ùå Error training K-Nearest Neighbors: {e}")
    
    async def _train_naive_bayes(self, X_train, X_test, y_train, y_test):
        """Train Naive Bayes model"""
        try:
            logger.info("üßÆ Training Naive Bayes on authentic data...")
            
            self.models['naive_bayes'] = GaussianNB()
            
            self.models['naive_bayes'].fit(X_train, y_train)
            accuracy = self.models['naive_bayes'].score(X_test, y_test)
            logger.info(f"‚úÖ Naive Bayes accuracy: {accuracy:.3f}")
            self.model_names.append('Naive Bayes')
            
        except Exception as e:
            logger.error(f"‚ùå Error training Naive Bayes: {e}")
    
    def _prepare_training_data(self):
        """Prepare training data from authentic dataset"""
        try:
            # Filter for matches with complete data
            complete_matches = self.df[
                (self.df['FTHome'].notna()) & 
                (self.df['FTAway'].notna()) &
                (self.df['HomeElo'].notna()) &
                (self.df['AwayElo'].notna())
            ].copy()
            
            logger.info(f"üìä Preparing training data from {len(complete_matches)} complete matches")
            
            X = []
            y = []
            
            for _, match in complete_matches.iterrows():
                features = [
                    match['HomeElo'] if pd.notna(match['HomeElo']) else 1500,
                    match['AwayElo'] if pd.notna(match['AwayElo']) else 1500,
                    match['Form3Home'] if pd.notna(match['Form3Home']) else 0,
                    match['Form3Away'] if pd.notna(match['Form3Away']) else 0,
                    match['Form5Home'] if pd.notna(match['Form5Home']) else 0,
                    match['Form5Away'] if pd.notna(match['Form5Away']) else 0,
                ]
                
                # Determine result (0: Home win, 1: Away win, 2: Draw)
                home_score = match['FTHome']
                away_score = match['FTAway']
                
                if home_score > away_score:
                    result = 0
                elif away_score > home_score:
                    result = 1
                else:
                    result = 2
                
                X.append(features)
                y.append(result)
            
            return np.array(X), np.array(y)
            
        except Exception as e:
            logger.error(f"‚ùå Error preparing training data: {e}")
            return np.array([]), np.array([])
    
    def _build_team_elo_ratings(self):
        """Build team Elo ratings from authentic data"""
        try:
            latest_elo = {}
            
            for _, match in self.df.iterrows():
                if pd.notna(match['HomeElo']) and pd.notna(match['AwayElo']):
                    latest_elo[match['HomeTeam']] = match['HomeElo']
                    latest_elo[match['AwayTeam']] = match['AwayElo']
            
            self.team_elo = latest_elo
            logger.info(f"üìä Built Elo ratings for {len(self.team_elo)} teams")
            
        except Exception as e:
            logger.error(f"‚ùå Error building Elo ratings: {e}")
    
    def _extract_features(self, home_team: str, away_team: str) -> Optional[List[float]]:
        """Extract enhanced features using comprehensive authentic data"""
        try:
            from ml.enhanced_feature_extractor import EnhancedFeatureExtractor
            
            extractor = EnhancedFeatureExtractor()
            enhanced_features = extractor.extract_comprehensive_features(home_team, away_team, self.df)
            feature_vector = extractor.get_feature_vector(enhanced_features)
            
            return feature_vector.tolist()
            
        except Exception as e:
            logger.error(f"‚ùå Error extracting enhanced features for Reliable Ensemble: {e}")
            # Fallback to basic features
            home_elo = self._find_team_elo(home_team)
            away_elo = self._find_team_elo(away_team)
            
            if home_elo is None or away_elo is None:
                return None
            
            home_form = self._get_team_recent_form(home_team)
            away_form = self._get_team_recent_form(away_team)
            
            return [
                home_elo,
                away_elo,
                home_form['form3'],
                away_form['form3'],
                home_form['form5'],
                away_form['form5']
            ]
            
        except Exception as e:
            logger.error(f"‚ùå Error extracting features: {e}")
            return None
    
    def _find_team_elo(self, team_name: str) -> Optional[float]:
        """Find team Elo rating from authentic data"""
        if team_name in self.team_elo:
            return self.team_elo[team_name]
        
        # Try partial matches
        for team, elo in self.team_elo.items():
            if team_name.lower() in team.lower() or team.lower() in team_name.lower():
                return elo
        
        return None
    
    def _get_team_recent_form(self, team_name: str) -> Dict:
        """Get team's recent form from authentic data"""
        try:
            team_matches = self.df[
                (self.df['HomeTeam'].str.contains(team_name, na=False, case=False)) |
                (self.df['AwayTeam'].str.contains(team_name, na=False, case=False))
            ].copy()
            
            if len(team_matches) > 0:
                recent_match = team_matches.iloc[-1]
                
                form3 = 0
                form5 = 0
                
                if team_name.lower() in recent_match['HomeTeam'].lower():
                    form3 = recent_match.get('Form3Home', 0) if pd.notna(recent_match.get('Form3Home')) else 0
                    form5 = recent_match.get('Form5Home', 0) if pd.notna(recent_match.get('Form5Home')) else 0
                else:
                    form3 = recent_match.get('Form3Away', 0) if pd.notna(recent_match.get('Form3Away')) else 0
                    form5 = recent_match.get('Form5Away', 0) if pd.notna(recent_match.get('Form5Away')) else 0
                
                return {'form3': form3, 'form5': form5}
            
            return {'form3': 0, 'form5': 0}
            
        except Exception:
            return {'form3': 0, 'form5': 0}
    
    def _get_h2h_count(self, home_team: str, away_team: str) -> int:
        """Get head-to-head match count from authentic data"""
        try:
            h2h_matches = self.df[
                ((self.df['HomeTeam'].str.contains(home_team, na=False, case=False)) &
                 (self.df['AwayTeam'].str.contains(away_team, na=False, case=False))) |
                ((self.df['HomeTeam'].str.contains(away_team, na=False, case=False)) &
                 (self.df['AwayTeam'].str.contains(home_team, na=False, case=False)))
            ]
            
            return len(h2h_matches)
            
        except Exception:
            return 0